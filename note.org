* TODO tasks
** TODO restrict connectivity using mask, so easier for debug
** TODO gradient check dE/dW, dE/db
** TODO use tf to have a baseline for rnn
** TODO add variable time
** TODO implement a timer
** TODO implement a multiplier
total_loss = f(t) + loss | t is the time taken to from begin to output
** TODO handle variable length output
** DONE gradient check dO/dW, dO/db
** DONE current sgd is flawed, need stack (in fact not, just keep track in each computation step)
** DONE add batch training
** DONE use tf to have a baseline for nn
